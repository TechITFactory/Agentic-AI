# Security: Prompt Injection Defense

## Why this module
Protect the assistant from malicious docs and user prompts.

## Outcomes
- ✅ Add allowlist/denylist filters and content checks
- ✅ Enforce system prompts and output validation
- ✅ Log and block suspicious queries

**Time**: ~25 minutes

**Tasks
1) Implement basic filters and system prompt constraints
2) Validate outputs (JSON) before returning
3) Log blocked attempts

**Deliverable
- Security notes and code snippets for filters/validation

**Checkpoint
Would embedded “ignore instructions” text be neutralized by your defenses?