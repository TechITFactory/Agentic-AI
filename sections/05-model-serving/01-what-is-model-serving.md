# What Is Model Serving?

## Why this lesson
Understand why models become services, the constraints that introduces, and the basic components of an ML-serving stack.

## Outcomes
- ✅ Explain online vs batch serving and when to use each
- ✅ List the core pieces of a serving stack (model store, API, logging, monitoring)
- ✅ Identify latency, throughput, and cost trade-offs

**Time**: ~20 minutes

**Prerequisites**: Section 4 models and artifacts

## Agenda
- Batch vs online serving
- Typical request flow and components
- SLOs: latency, availability, correctness

## Hands-on
- Sketch a simple serving diagram for your churn model
- Define target latency and throughput for a hypothetical API

## Deliverable
- A short markdown note with your serving diagram and SLOs

## Checkpoint
Can you defend why you’d pick online or batch serving for a given business scenario?