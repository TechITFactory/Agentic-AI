# Section 5: Model Serving (API for Predictions)

## Overview

Turn ML models into production APIs using FastAPI. Learn to serve predictions at scale with proper validation and monitoring.

## What You'll Learn

1. **Model Serving Concepts**: Why APIs for ML?
2. **FastAPI Basics**: Building REST APIs for ML
3. **Prediction Endpoints**: /predict, /batch_predict
4. **Input Validation**: Pydantic schemas for data validation
5. **Logging**: Safe request/response logging
6. **Load Testing**: Testing API performance (hey/ab)
7. **Mini Lab**: Run prediction API locally

## Duration

**Estimated Time**: 8-10 hours

## Prerequisites

- Section 4 completed (ML models)
- Basic understanding of APIs (we'll teach FastAPI)

## What You'll Build

A production-ready prediction API with:
- Model loading and caching
- Input validation
- Error handling
- Request logging
- Performance testing

## What's Next?

Move to [Section 6: Containers & Deployment](../06-containers-deployment/README.md) to containerize and deploy your API.
