# Section 8: Intro to LLMs (No Fluff)

## Overview

Get a practical, jargon-free introduction to large language models. Learn how tokens, temperatures, and prompt patterns actually affect outputs, and build a JSON-only assistant to practice structured responses.

## What You'll Learn

1. **What an LLM Is**: How they really work
2. **Tokens & Context**: Why context window limits matter
3. **Decoding Controls**: Temperature and top-p
4. **Prompt Patterns**: Zero-shot, few-shot, structured output
5. **JSON Mode**: Schema validation for safe outputs
6. **Tool/Function Calling**: Core concept for agents
7. **Mini Lab**: Build a JSON-only assistant

## Lessons

1. [LLM Fundamentals](./01-llm-fundamentals.md)
2. [Tokens and Context Windows](./02-tokens-context.md)
3. [Controlling Output: Temperature & Top-p](./03-decoding-controls.md)
4. [Prompt Patterns](./04-prompt-patterns.md)
5. [JSON Mode and Schema Validation](./05-json-mode.md)
6. [Tool and Function Calling Concepts](./06-tool-calling.md)
7. [Mini Lab: JSON-Only Assistant](./07-mini-lab-json-assistant.md)

## Duration

**Estimated Time**: 8-10 hours

## Prerequisites

- Section 7 completed (MLOps Foundations)
- Comfortable with Python

## What You'll Build

- Prompt templates for common patterns
- A JSON-only assistant that validates schema outputs

## Section Structure

```text
sections/08-intro-llms/
├── README.md
├── 01-llm-fundamentals.md
├── 02-tokens-context.md
├── 03-decoding-controls.md
├── 04-prompt-patterns.md
├── 05-json-mode.md
├── 06-tool-calling.md
└── 07-mini-lab-json-assistant.md
```text
## What's Next?

Move to [Section 9: Embeddings & Vector Databases](../09-embeddings-vector-dbs/README.md) to prepare for RAG.
